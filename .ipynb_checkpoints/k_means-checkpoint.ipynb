{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c8eb4f-095d-40ad-b1b0-c293a52d7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11d479-a155-42e3-84e2-64c10b99709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things we want to capture:\n",
    "# tangible equity/tangible asset -> we need tangible equity and tangible asset \n",
    "# - supposed to show the banks we're interested in don't have a very high EQUITY PERCENT relative to their ASSETS\n",
    "# leverage ratio, apparently this is diff than tang asset percent\n",
    "# Also use total debt / total assets == leverage\n",
    "# leverage ratio = tier 1 capital / total consolidated assets\n",
    "# tier 1 capital = shareholders equity + retained earnings\n",
    "\n",
    "# gonna use long term debt / short term debt ratio\n",
    "\n",
    "\n",
    "list_files = os.listdir(\"./assetsheets\")\n",
    "num_files = len(list_files)\n",
    "arr = []\n",
    "for file in list_files:\n",
    "    file_path = \"./assetsheets/\" + file\n",
    "    total_str = \"\"\n",
    "    if (os.path.isfile(file_path)):\n",
    "        with open(file_path,encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter='\\n')\n",
    "            for row in csv_reader:\n",
    "                x = \"\".join(row)\n",
    "                total_str += x\n",
    "    arr.append(total_str)\n",
    "\n",
    "    \n",
    "svb_coords = []\n",
    "sigbank_coords =[]\n",
    "dict_data = {}\n",
    "for data,bank in zip(arr,list_files):\n",
    "#     print(data,bank)\n",
    "    try:\n",
    "#         print(bank)\n",
    "        equity_tang_asset = data.split(\"Total Shareholders\\' Equity / Total Assets\")[1].split(\"Return On Average Total Equity\")[0].replace(\",\",\"\")\n",
    "        split_eq = equity_tang_asset.split(\"%\")\n",
    "        last_eq = split_eq[0]\n",
    "        total_asset_debt = data.split(\"Assets - Total Growth\")[1].split(\"Return On Average\")[0].replace(\",\",\"\")\n",
    "        split_debt = total_asset_debt.split('%')\n",
    "        last_tad = split_debt[0]\n",
    "#         print(last_eq,last_tad)\n",
    "        dict_data[bank] = [last_eq,last_tad]\n",
    "#         print(last_eq,last_tad)\n",
    "        if bank == '\"SVB Financial Group**(Failed - Shutdown on Mar 10 2023)**\".csv':\n",
    "            svb_coords = [float(last_eq),float(last_tad)]\n",
    "        elif bank == '\"Signature Bank **(Failed - Shutdown on Mar 12 2023)**\".csv':\n",
    "            sigbank_coords = [float(last_eq),float(last_tad)]\n",
    "        \n",
    "            \n",
    "        \n",
    "    except:\n",
    "        # cant find total equity / total assets\n",
    "        pass\n",
    "# print(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e00077-d870-45c9-87a0-6b483190db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for value in dict_data.values():\n",
    "    x.append(float(value[0]))\n",
    "    y.append(float(value[1]))\n",
    "plt.scatter(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c9ff6-8722-468c-8de1-139e00ae1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for value in dict_data.values():\n",
    "    x.append(float(value[0]))\n",
    "    y.append(float(value[1]))\n",
    "plt.scatter(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fa8ac-8a70-45e2-a049-c5bdd8d6ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euc_distance(pokemon1, pokemon2):\n",
    "    #Do the thing\n",
    "    return np.sqrt(np.sum((pokemon1-pokemon2)**2))\n",
    "\n",
    "def jacc_distance(pokemon1, pokemon2):\n",
    "    pokemon1 = set(pokemon1)\n",
    "    pokemon2 = set(pokemon2)\n",
    "\n",
    "    #Find symmetric difference of two sets\n",
    "    nominator = pokemon1.symmetric_difference(pokemon2)\n",
    "\n",
    "    #Find union of two sets\n",
    "    denominator = pokemon1.union(pokemon2)\n",
    "\n",
    "    #Take the ratio of sizes\n",
    "    distance = len(nominator)/len(denominator)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def jacc_euc_distance(x1, x2):\n",
    "    return jacc_distance(x1[0], x2[0]) + euc_distance(x1[1:], x2[1:])\n",
    "\n",
    "def weighted_jacc_euc_distance(pokemon1, pokemon2, a=.9): #a is the \"percentage\" that we'll weight Jaccard\n",
    "    dist=100*(1-a)*euc_distance(x1[1:], x2[1:])+100*a*jacc_distance(x1[0], x2[0])\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c2709-a217-4d62-9d23-f7744a3ff6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(df, distance=distance, k=4, tol=0.05): \n",
    "    \"\"\"\n",
    "    Usage: input \n",
    "        df=data frame, \n",
    "        k=# of clusters\n",
    "        tol=tolerance for L_2 convergance check on centroids\n",
    "    \"\"\" \n",
    "    #preperations of data\n",
    "    X = df.values\n",
    "    \n",
    "    # Initializing Clusters\n",
    "    iterations = 0\n",
    "    diff = 1\n",
    "    cluster = np.zeros(X.shape[0])\n",
    "    centroids = data.sample(n=k).values\n",
    "    error = None\n",
    "    \n",
    "    while diff:\n",
    "        # for each observation\n",
    "        distances = np.zeros(X.shape[0])\n",
    "        for i, row in enumerate(X):\n",
    "            minDist = float('inf')\n",
    "            # dist of the point from all centroids\n",
    "            for idx, centroid in enumerate(centroids):\n",
    "                d = distance(centroid, row)\n",
    "                # store closest centroid\n",
    "                if minDist > d:\n",
    "                    minDist = d\n",
    "                    distances[i] = minDist\n",
    "                    cluster[i] = idx\n",
    "        \n",
    "        #calculate reconstruction error\n",
    "        newError = np.sum(distances)\n",
    "        \n",
    "        numericCentroids = pd.DataFrame(X)[[1,2,3]].groupby(by=cluster).mean().values\n",
    "        \n",
    "        typeCentroids=[]\n",
    "        for i in range(k):\n",
    "            currK = []\n",
    "            for j in range(X.shape[0]):\n",
    "                if i == cluster[j]:\n",
    "                    currK.append(X[:,0][j])       \n",
    "            \n",
    "            typeCentroids.append(set().union(currK))\n",
    "        \n",
    "        centroids = []\n",
    "        for i in range(k):\n",
    "            temp = list(numericCentroids[i])\n",
    "            temp.insert(0, typeCentroids[i])\n",
    "            centroids.append(temp)\n",
    "                \n",
    "        if iterations>1:\n",
    "             if error - newError <=tol:\n",
    "                diff = 0\n",
    "        \n",
    "        error = newError\n",
    "                \n",
    "        iterations +=1\n",
    "\n",
    "    return centroids, cluster, error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
